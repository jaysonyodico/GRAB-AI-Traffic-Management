{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab A.I. for SEA Challenge: Traffic Management\n",
    "\n",
    "Jayson Yodico <br>\n",
    "Asian Institute of Management\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Understanding congestion dynamics is indispensable in solving traffic congestion.\n",
    "\n",
    "This project seeks to accurately forecast travel demand on a specific area and time based on historical Grab bookings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T14:55:46.048115Z",
     "start_time": "2019-06-15T14:55:39.716713Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import pygeohash as gh\n",
    "\n",
    "import scipy\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.layers import Dense, LSTM, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import itertools\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T14:56:20.278850Z",
     "start_time": "2019-06-15T14:55:51.342138Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geohash6</th>\n",
       "      <th>day</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qp03wc</td>\n",
       "      <td>18</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>0.020072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qp03pn</td>\n",
       "      <td>10</td>\n",
       "      <td>14:30:00</td>\n",
       "      <td>0.024721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qp09sw</td>\n",
       "      <td>9</td>\n",
       "      <td>06:15:00</td>\n",
       "      <td>0.102821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qp0991</td>\n",
       "      <td>32</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>0.088755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qp090q</td>\n",
       "      <td>15</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>0.074468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  geohash6  day timestamp    demand\n",
       "0   qp03wc   18  20:00:00  0.020072\n",
       "1   qp03pn   10  14:30:00  0.024721\n",
       "2   qp09sw    9  06:15:00  0.102821\n",
       "3   qp0991   32  05:00:00  0.088755\n",
       "4   qp090q   15  04:00:00  0.074468"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv('Traffic Management/training.csv')\n",
    "raw_df['timestamp'] = pd.to_datetime(raw_df['timestamp'], format= '%H:%M').dt.time\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T14:50:52.035024Z",
     "start_time": "2019-06-15T14:50:51.408811Z"
    }
   },
   "outputs": [],
   "source": [
    "# CREATE DUMMY DATETIME VALUES\n",
    "dates = pd.DataFrame()\n",
    "dates['dummy_date'] = pd.date_range(start=pd.datetime(2019, 1, 1),\n",
    "                              periods=len(raw_df.day.unique())+1)\n",
    "dates['day'] = np.arange(1, dates.shape[0] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T14:50:53.810357Z",
     "start_time": "2019-06-15T14:50:53.480741Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>T_n</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:15:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:30:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:45:00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp  T_n  day\n",
       "0  00:00:00    0    1\n",
       "1  00:15:00    1    1\n",
       "2  00:30:00    2    1\n",
       "3  00:45:00    3    1\n",
       "4  01:00:00    4    1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timenum = pd.DataFrame(pd.date_range(start=dates.dummy_date.min(),\n",
    "                                     end=dates.dummy_date.max(),\n",
    "                                     freq='15min'), columns=['dummy_datetime'])\n",
    "\n",
    "timenum['dummy_date'] = pd.to_datetime(timenum['dummy_datetime'].dt.date)\n",
    "timenum['timestamp'] = timenum['dummy_datetime'].dt.time\n",
    "\n",
    "timenum['T_n'] = np.arange(timenum.shape[0])\n",
    "timenum = timenum.merge(dates, on='dummy_date', how='left')\n",
    "\n",
    "del timenum['dummy_datetime'], timenum['dummy_date']\n",
    "timenum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T14:51:26.890173Z",
     "start_time": "2019-06-15T14:51:24.148389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geohash6</th>\n",
       "      <th>day</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>demand</th>\n",
       "      <th>T_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qp03wc</td>\n",
       "      <td>18</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>0.020072</td>\n",
       "      <td>1712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qp03pn</td>\n",
       "      <td>10</td>\n",
       "      <td>14:30:00</td>\n",
       "      <td>0.024721</td>\n",
       "      <td>922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qp09sw</td>\n",
       "      <td>9</td>\n",
       "      <td>06:15:00</td>\n",
       "      <td>0.102821</td>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qp0991</td>\n",
       "      <td>32</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>0.088755</td>\n",
       "      <td>2996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qp090q</td>\n",
       "      <td>15</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>0.074468</td>\n",
       "      <td>1360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  geohash6  day timestamp    demand   T_n\n",
       "0   qp03wc   18  20:00:00  0.020072  1712\n",
       "1   qp03pn   10  14:30:00  0.024721   922\n",
       "2   qp09sw    9  06:15:00  0.102821   793\n",
       "3   qp0991   32  05:00:00  0.088755  2996\n",
       "4   qp090q   15  04:00:00  0.074468  1360"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SET AS DATETIME INDICES\n",
    "df = raw_df.merge(timenum, on=['day', 'timestamp'], how='left')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T14:52:00.661186Z",
     "start_time": "2019-06-15T14:51:35.096756Z"
    }
   },
   "outputs": [],
   "source": [
    "g = df.groupby(['geohash6'])\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for loc in g.groups.keys():\n",
    "    \n",
    "    test = g.get_group(loc)\n",
    "\n",
    "    dummy = timenum[(timenum.T_n >= test.T_n.min())\n",
    "                    & (timenum.T_n <= test.T_n.max())]\n",
    "    dummy = dummy.merge(test[['T_n', 'demand']], on='T_n', how='left').fillna(0)\n",
    "    dummy['geohash6'] = loc\n",
    "    dummy['lat'] = gh.decode(loc)[0]\n",
    "    dummy['long'] = gh.decode(loc)[1]\n",
    "    \n",
    "    all_data.append(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T14:52:08.503983Z",
     "start_time": "2019-06-15T14:52:03.131135Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>T_n</th>\n",
       "      <th>day</th>\n",
       "      <th>demand</th>\n",
       "      <th>geohash6</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02:45:00</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020592</td>\n",
       "      <td>qp02yc</td>\n",
       "      <td>-5.48</td>\n",
       "      <td>90.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03:00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010292</td>\n",
       "      <td>qp02yc</td>\n",
       "      <td>-5.48</td>\n",
       "      <td>90.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03:15:00</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>qp02yc</td>\n",
       "      <td>-5.48</td>\n",
       "      <td>90.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03:30:00</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>qp02yc</td>\n",
       "      <td>-5.48</td>\n",
       "      <td>90.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03:45:00</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>qp02yc</td>\n",
       "      <td>-5.48</td>\n",
       "      <td>90.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp  T_n  day    demand geohash6   lat  long\n",
       "0  02:45:00   11    1  0.020592   qp02yc -5.48  90.7\n",
       "1  03:00:00   12    1  0.010292   qp02yc -5.48  90.7\n",
       "2  03:15:00   13    1  0.000000   qp02yc -5.48  90.7\n",
       "3  03:30:00   14    1  0.000000   qp02yc -5.48  90.7\n",
       "4  03:45:00   15    1  0.000000   qp02yc -5.48  90.7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat(all_data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T14:54:25.689353Z",
     "start_time": "2019-06-15T14:52:25.874947Z"
    }
   },
   "outputs": [],
   "source": [
    "# data.to_csv('Traffic Management/training_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE ENGINEERING AND MODELING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T14:56:35.303929Z",
     "start_time": "2019-06-15T14:56:34.220112Z"
    }
   },
   "outputs": [],
   "source": [
    "def denoise(series, pctile):\n",
    "\n",
    "    sff = scipy.fft(series)    \n",
    "    abs_sff = abs(sff)\n",
    "    sff[abs_sff < np.percentile(abs_sff, q=pctile)] = 0\n",
    "    cleaned_series = np.abs(scipy.ifft(sff))\n",
    "\n",
    "    return cleaned_series\n",
    "\n",
    "def create_trainval_test(data, pctile, max_window, frac=0.001):\n",
    "\n",
    "    i = 0\n",
    "    g = data.groupby('geohash6')\n",
    "    \n",
    "    for each_gh in g.groups.keys():\n",
    "        dummy = g.get_group(each_gh).copy()\n",
    "        dummy['demand_fft'] = denoise(dummy.demand.values, pctile)\n",
    "\n",
    "        for fwd in range(-2,-6,-1):\n",
    "            dummy[f'demand+{-1*fwd}'] = dummy['demand'].shift(fwd+1)\n",
    "            dummy[f'demand_fft+{-1*fwd}'] = dummy['demand_fft'].shift(fwd+1)\n",
    "\n",
    "        for bwd in range(1, 6):\n",
    "            dummy[f'demand-{bwd}'] = dummy['demand'].shift(bwd)\n",
    "\n",
    "        for bwd in range(1, max_window + 1):\n",
    "            dummy[f'demand_fft-{bwd}'] = dummy['demand_fft'].shift(bwd)\n",
    "\n",
    "        dummy = dummy.dropna()\n",
    "        len_dummy = dummy.shape[0]\n",
    "        sp1, sp2 = int(len_dummy*0.6), int(len_dummy*0.8)\n",
    "\n",
    "        trn = dummy.iloc[:sp1,:].sample(frac=frac)\n",
    "        vl = dummy.iloc[sp1:sp2,:].sample(frac=frac)\n",
    "        tst = dummy.iloc[sp2:,:].sample(frac=frac)\n",
    "\n",
    "        if i == 0:\n",
    "            trn.to_csv('train1.csv', index=False)\n",
    "            vl.to_csv('val1.csv', index=False)\n",
    "            tst.to_csv('test1.csv', index=False)\n",
    "\n",
    "        else:\n",
    "            trn.to_csv('train1.csv', mode='a', header=False, index=False)\n",
    "            vl.to_csv('val1.csv', mode='a', header=False, index=False)\n",
    "            tst.to_csv('test1.csv', mode='a', header=False, index=False)  \n",
    "        \n",
    "        i+=1\n",
    "            \n",
    "    train = pd.read_csv('train1.csv')\n",
    "    val = pd.read_csv('val1.csv')\n",
    "    test = pd.read_csv('test1.csv')\n",
    "    \n",
    "    return train, val, test\n",
    "\n",
    "def split(train, val, test):\n",
    "\n",
    "    toremove_feat = ['demand','demand+2', 'demand+3','demand+4', 'demand+5',\n",
    "                     'demand_fft','demand_fft+2', 'demand_fft+3','demand_fft+4',\n",
    "                     'demand_fft+5','demand-1', 'demand-2', 'demand-3',\n",
    "                     'demand-4','demand-5', 'geohash6']\n",
    "\n",
    "    targets = ['demand_fft', 'demand_fft+2', 'demand_fft+3', 'demand_fft+4',\n",
    "               'demand_fft+5']\n",
    "    \n",
    "    tags = ['geohash6']\n",
    "\n",
    "    targets_actual = ['demand', 'demand+2', 'demand+3', 'demand+4', 'demand+5']\n",
    "\n",
    "    X_train = train.drop(toremove_feat, axis=1)\n",
    "    y_train = train[targets]\n",
    "    train_tag = train[tags]\n",
    "\n",
    "    X_val = val.drop(toremove_feat, axis=1)\n",
    "    y_val = val[targets]\n",
    "    val_tag = val[tags]\n",
    "\n",
    "    X_test = test.drop(toremove_feat, axis=1)\n",
    "    y_test = test[targets_actual]\n",
    "    test_tag = test[tags]\n",
    "    \n",
    "    return (X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "            train_tag, val_tag, test_tag)\n",
    "\n",
    "\n",
    "def fit_model(filepath, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    \n",
    "    n_rows, n_cols = X_train.shape\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_cols, input_dim = n_cols, kernel_initializer='uniform',\n",
    "                    activation='linear'))\n",
    "    model.add(Dense(n_cols*5, kernel_initializer='uniform',\n",
    "                    activation='relu'))\n",
    "    model.add(Dense(5, kernel_initializer='uniform', activation='linear'))\n",
    "    \n",
    "    lrs = [0.001, 0.0001]\n",
    "    patience_vals = [10, 100]\n",
    "    epoch_vals = [50, 500]\n",
    "    \n",
    "    for ind in range(len(lrs)):\n",
    "    \n",
    "        model.compile(loss='mean_squared_error',\n",
    "                      optimizer=optimizers.RMSprop(lr=lrs[ind]),\n",
    "                      metrics=['mean_squared_error'])\n",
    "\n",
    "        mc = ModelCheckpoint(filepath, monitor='val_mean_squared_error',\n",
    "                                 verbose=0, save_best_only=True,\n",
    "                                 mode='min')\n",
    "\n",
    "        es = EarlyStopping(monitor='val_mean_squared_error',\n",
    "                           patience=patience_vals[ind], verbose=0,\n",
    "                           min_delta=0.00001)\n",
    "\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                  epochs=epoch_vals[ind], batch_size=1024*32,\n",
    "                  callbacks=[es, mc],\n",
    "                  verbose=0)\n",
    "\n",
    "        model = load_model(filepath)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate(model, X_test, y_test):\n",
    "    \n",
    "    preds = model.predict(X_test)\n",
    "    a1 = mean_squared_error(preds[:,0].ravel(), y_test['demand'].values)\n",
    "    a2 = mean_squared_error(preds[:,1].ravel(), y_test['demand+2'].values)\n",
    "    a3 = mean_squared_error(preds[:,2].ravel(), y_test['demand+3'].values)\n",
    "    a4 = mean_squared_error(preds[:,3].ravel(), y_test['demand+4'].values)\n",
    "    a5 = mean_squared_error(preds[:,4].ravel(), y_test['demand+5'].values)\n",
    "\n",
    "    fitness = np.mean([a1, a2, a3, a4, a5])\n",
    "    \n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENETIC ALGORITHM FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T14:56:37.411232Z",
     "start_time": "2019-06-15T14:56:37.040454Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_testmse(data, pctile, window):\n",
    "    \n",
    "    train, val, test = create_trainval_test(data=data, pctile=pctile,\n",
    "                                            max_window= window)\n",
    "    \n",
    "    print('Creating Data: Done', end='\\t')\n",
    "    \n",
    "    (X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "     train_tag, val_tag, test_tag) = split(train, val, test)\n",
    "    \n",
    "    model = fit_model('model.hdf5', X_train, y_train,\n",
    "                      X_val, y_val, X_test, y_test)\n",
    "    \n",
    "    print('Model Fitting: Done', end='\\t')\n",
    "    \n",
    "    fitness = evaluate(model, X_test, y_test)\n",
    "    \n",
    "    print(f'Fitness = {fitness}')\n",
    "    \n",
    "    return fitness\n",
    "\n",
    "def mate(fittest, mating_pairs, n_children):\n",
    "    \n",
    "    species = np.zeros((n_species, len_gene), dtype=int)\n",
    "    species[0] = fittest\n",
    "\n",
    "    i = 1   \n",
    "    for father, mother in mating_pairs: \n",
    "        \n",
    "        parents = [father, mother]\n",
    "        np.random.shuffle(parents)\n",
    "        \n",
    "        child = np.zeros(len_gene, dtype=int)\n",
    "        \n",
    "        child[:1] = parents[0][:1]\n",
    "        child[1:] = parents[1][1:]\n",
    "\n",
    "        species[i] = child\n",
    "        i += 1\n",
    "        if i == n_children: break\n",
    "\n",
    "    return species\n",
    "\n",
    "def mutate(species, mutation_rate):\n",
    "    \n",
    "    n_species = species.shape[0]\n",
    "    n_mutate = int(mutation_rate*(n_species - 1))\n",
    "\n",
    "    inds_mut = np.random.randint(1, n_species, size=n_mutate)\n",
    "    species[inds_mut, 0] = np.random.choice(np.arange(min_pctile, max_pctile, 5), n_mutate)\n",
    "\n",
    "    inds_mut = np.random.randint(1, n_species, size=n_mutate)\n",
    "    species[inds_mut, 1] = np.random.choice(np.arange(min_window, max_window, 4), n_mutate)\n",
    "   \n",
    "    return species\n",
    "\n",
    "def diversify(sp):\n",
    "    \n",
    "    col_to_change = np.random.choice(list(range(len_gene)))\n",
    "    \n",
    "    if col_to_change == 0:\n",
    "        sp[0] = np.random.choice(np.arange(min_pctile, max_pctile, 5),1)# PERCENTILE\n",
    "    \n",
    "    elif col_to_change == 1:\n",
    "        sp[1] = np.random.choice(np.arange(min_window, max_window, 4), 1)\n",
    "    \n",
    "    return sp\n",
    "\n",
    "def add_to_records(all_records, species, fitness_values):\n",
    "    \n",
    "    res_gen = pd.DataFrame(species, columns=['percentile', 'window'])\n",
    "    res_gen['gen'] = gen\n",
    "    res_gen['index'] = list(range(n_species))\n",
    "    res_gen['fitness_test_mse'] = fitness_values\n",
    "    \n",
    "    all_records = pd.concat([all_records, res_gen])\n",
    "    all_records.to_csv('all_records.csv', index=False)\n",
    "    \n",
    "    return all_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T14:57:08.601152Z",
     "start_time": "2019-06-15T14:56:46.978218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geohash6</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qp02yc</td>\n",
       "      <td>-5.48</td>\n",
       "      <td>90.7</td>\n",
       "      <td>0.020592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qp02yc</td>\n",
       "      <td>-5.48</td>\n",
       "      <td>90.7</td>\n",
       "      <td>0.010292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qp02yc</td>\n",
       "      <td>-5.48</td>\n",
       "      <td>90.7</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qp02yc</td>\n",
       "      <td>-5.48</td>\n",
       "      <td>90.7</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qp02yc</td>\n",
       "      <td>-5.48</td>\n",
       "      <td>90.7</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  geohash6   lat  long    demand\n",
       "0   qp02yc -5.48  90.7  0.020592\n",
       "1   qp02yc -5.48  90.7  0.010292\n",
       "2   qp02yc -5.48  90.7  0.000000\n",
       "3   qp02yc -5.48  90.7  0.000000\n",
       "4   qp02yc -5.48  90.7  0.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Traffic Management/training_processed.csv')\n",
    "df = df.sort_values(['geohash6', 'T_n'])\n",
    "\n",
    "del df['timestamp'], df['T_n'], df['day']\n",
    "\n",
    "data = df[['geohash6', 'lat', 'long', 'demand']].copy()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T14:06:31.126891Z",
     "start_time": "2019-06-15T14:06:31.119631Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7556911, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-15T13:46:48.076Z"
    }
   },
   "outputs": [],
   "source": [
    "# g = data.groupby('geohash6')\n",
    "# all_corrs = []\n",
    "# for pctile in range(10,100, 10):\n",
    "\n",
    "#     all_gh = []\n",
    "    \n",
    "#     for each_gh in g.groups.keys():\n",
    "\n",
    "#         dummy = g.get_group(each_gh).copy()\n",
    "#         dummy['demand_fft'] = denoise(dummy.demand.values, pctile)\n",
    "#         all_gh.append(dummy)\n",
    "        \n",
    "#     all_dfs = pd.concat(all_gh)\n",
    "#     corr = np.corrcoef(all_dfs.demand.values, all_dfs.demand_fft.values)[0,1]\n",
    "#     all_corrs.append(corr)\n",
    "    \n",
    "# fig = plt.figure()\n",
    "# plt.plot(range(10,100, 10), all_corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENETIC ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T01:56:58.424379Z",
     "start_time": "2019-06-16T01:56:58.399492Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "res_file = 'all_records.csv'\n",
    "exists = os.path.isfile(res_file)\n",
    "\n",
    "n_species = 10\n",
    "len_gene = 2\n",
    "max_gen = 10\n",
    "mut_rates = np.linspace(0, 0.5, max_gen)\n",
    "n_select = 5\n",
    "\n",
    "min_pctile, max_pctile = 5, 100\n",
    "min_window, max_window = 4, 100\n",
    "\n",
    "col_names = ['percentile', 'window', 'gen', 'index', 'fitness_test_mse']\n",
    "gene_names = ['percentile', 'window']\n",
    "\n",
    "tested_species = np.array([-99,-99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T01:57:14.785339Z",
     "start_time": "2019-06-16T01:57:14.666090Z"
    }
   },
   "outputs": [],
   "source": [
    "if exists:\n",
    "    results_df = pd.read_csv(res_file)\n",
    "    tested_species = results_df[gene_names].values\n",
    "    recent_results = results_df[results_df['gen'] == max(results_df['gen'])][col_names].reset_index(drop=True)\n",
    "\n",
    "    num_generations = list(range(max(results_df['gen'])+1, max_gen))\n",
    "\n",
    "    mating_pool = recent_results[gene_names].values[:n_select]\n",
    "    mating_pairs = list(itertools.combinations(mating_pool, 2))    \n",
    "    np.random.shuffle(mating_pairs)    \n",
    "    \n",
    "    recent_results = recent_results.sort_values('fitness_test_mse')\n",
    "    fittest_val = recent_results.iloc[0]['fitness_test_mse']\n",
    "    fittest = recent_results.iloc[0][gene_names].values.astype(int)\n",
    "    \n",
    "    species = mate(fittest=fittest, mating_pairs=mating_pairs,\n",
    "               n_children=n_species)\n",
    "    species = mutate(species, mutation_rate=mut_rates[num_generations[0]])\n",
    "    \n",
    "    tested_species = results_df[gene_names].values\n",
    "    \n",
    "else:\n",
    "    \n",
    "    num_generations = list(range(0,max_gen))\n",
    "    results_df = pd.DataFrame(columns=col_names)\n",
    "    \n",
    "    # INITIALIZE VALUES\n",
    "    species = np.zeros((n_species, len_gene), dtype=int)\n",
    "    species[:,0] = np.random.choice(np.arange(min_pctile, max_pctile, 5), n_species)\n",
    "    species[:,1] = np.random.choice(np.arange(min_window, max_window, 4), n_species)    \n",
    "    tested_species = np.array([-99,-99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T01:57:16.366208Z",
     "start_time": "2019-06-16T01:57:16.359715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45, 92],\n",
       "       [95, 92],\n",
       "       [95, 52],\n",
       "       [35, 92],\n",
       "       [55, 92],\n",
       "       [45, 12],\n",
       "       [95, 36],\n",
       "       [55, 36],\n",
       "       [25, 36],\n",
       "       [35, 92]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T01:57:20.702967Z",
     "start_time": "2019-06-16T01:57:20.688044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45, 92],\n",
       "       [30, 96],\n",
       "       [95, 52],\n",
       "       [35, 92],\n",
       "       [55, 92],\n",
       "       [45, 12],\n",
       "       [95, 36],\n",
       "       [55, 36],\n",
       "       [25, 36],\n",
       "       [35, 92]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species[1,:] = np.array([30, 96])\n",
    "\n",
    "#for j, sp in enumerate(species):\n",
    "#    if j == 0:\n",
    "#        continue\n",
    "\n",
    "#     elif j > 0:\n",
    "#         while sp.tolist() in tested_species.tolist():\n",
    "#             sp = diversify(sp)\n",
    "            \n",
    "species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-16T01:57:23.799Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation 7:\n",
      "[45 92] Done\tFitness = 0.0019635655589860857\n",
      "[30 96] Creating Data: Done\tModel Fitting: Done\tFitness = 0.0021741406306411805\n",
      "[95 52] Creating Data: Done\tModel Fitting: Done\tFitness = 0.0035068740180920857\n",
      "[35 92] Creating Data: Done\t"
     ]
    }
   ],
   "source": [
    "for gen in num_generations:\n",
    "    \n",
    "    print(f'generation {gen}:')\n",
    "    fitness_values = []\n",
    "    \n",
    "    for j, sp in enumerate(species):\n",
    "\n",
    "        if gen == 0:\n",
    "            print(sp, end=' ')\n",
    "            fitness = calculate_testmse(data, sp[0], sp[1])   \n",
    "            tested_species = np.vstack([tested_species, sp])\n",
    "\n",
    "        elif gen > 0:\n",
    "            if j == 0:\n",
    "                print(sp, 'Done', end='\\t')\n",
    "                fitness = fittest_val\n",
    "                print(f'Fitness = {fitness}')\n",
    "\n",
    "            elif j > 0:\n",
    "                while sp.tolist() in tested_species.tolist():\n",
    "                    sp = diversify(sp)\n",
    "                print(sp, end=' ')\n",
    "                species[j,:] = sp\n",
    "                fitness = calculate_testmse(data, sp[0], sp[1])    \n",
    "                tested_species = np.vstack([tested_species, sp])\n",
    "\n",
    "        fitness_values.append(fitness)\n",
    "\n",
    "    res_gen = pd.DataFrame(species, columns=gene_names)\n",
    "    res_gen['gen'] = gen\n",
    "    res_gen['index'] = list(range(n_species))\n",
    "    res_gen['fitness_test_mse'] = fitness_values\n",
    "    \n",
    "    results_df = pd.concat([results_df, res_gen])\n",
    "    results_df.to_csv(res_file, index=False)\n",
    "\n",
    "    fittest, fittest_val = (species[np.argmin(fitness_values)],\n",
    "                            np.min(fitness_values))\n",
    "    \n",
    "    print(f'Fittest:{fittest} {fittest_val}')\n",
    "    print('==================================')\n",
    "    \n",
    "    species = species[np.argsort(fitness_values)]\n",
    "    mating_pool = species[:n_select]\n",
    "    mating_pairs = list(itertools.combinations(mating_pool, 2))    \n",
    "    np.random.shuffle(mating_pairs)\n",
    "    \n",
    "    species = mate(fittest=fittest, mating_pairs=mating_pairs,\n",
    "                   n_children=n_species)\n",
    "    \n",
    "    species = mutate(species, mutation_rate=mut_rates[gen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.0016134498430449714"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASELINE ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T12:35:05.568655Z",
     "start_time": "2019-06-14T12:35:05.507169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0275126235967825,\n",
       " 0.034559915748419066,\n",
       " 0.04001677974234045,\n",
       " 0.044955243093510726,\n",
       " 0.04993596338276819)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "b1 = np.sqrt(mean_squared_error(test['demand'].values,\n",
    "                                test['demand-1'].values))\n",
    "\n",
    "b2 = np.sqrt(mean_squared_error(test['demand'].values,\n",
    "                                test['demand-2'].values))\n",
    "\n",
    "b3 = np.sqrt(mean_squared_error(test['demand'].values,\n",
    "                                test['demand-3'].values))\n",
    "\n",
    "b4 = np.sqrt(mean_squared_error(test['demand'].values,\n",
    "                                test['demand-4'].values))\n",
    "\n",
    "b5 = np.sqrt(mean_squared_error(test['demand'].values,\n",
    "                                test['demand-5'].values))\n",
    "\n",
    "b1, b2, b3, b4, b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T09:06:12.415992Z",
     "start_time": "2019-06-14T09:06:12.362907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.039370885265768776"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([b1, b2, b3, b4, b5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
